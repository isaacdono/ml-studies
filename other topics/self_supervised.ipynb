{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2rFGCUpVjmHYvME+FwfPQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacdono/ml-studies/blob/main/other%20topics/self_supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estudo Prático: Aprendizado Autossupervisionado (SSL)\n",
        "\n",
        "O Aprendizado Autossupervisionado é uma técnica que preenche a lacuna entre o aprendizado supervisionado (que requer muitos dados rotulados) e o não supervisionado.\n",
        "\n",
        "A ideia central é **gerar os próprios rótulos a partir dos dados não rotulados**. Para isso, criamos uma **tarefa de pretexto (pretext task)**, onde o modelo aprende a prever alguma propriedade dos próprios dados. Ao resolver essa tarefa, o modelo é forçado a aprender representações (features) ricas e úteis sobre a estrutura dos dados.\n",
        "\n",
        "Neste notebook, vamos implementar uma forma popular de SSL chamada **Aprendizado Contrastivo**, inspirada no framework **SimCLR**.\n",
        "\n",
        "**O Plano:**\n",
        "1.  **Tarefa de Pretexto:** Pegaremos uma imagem, criaremos duas versões aumentadas (distorcidas) dela e treinaremos um modelo para \"saber\" que essas duas versões vieram da mesma imagem original, distinguindo-as de versões de outras imagens.\n",
        "2.  **Aprendizado de Representação:** Ao fazer isso, o modelo (um Encoder) aprenderá a extrair as características essenciais de uma imagem, ignorando as variações de cor, rotação, etc.\n",
        "3.  **Tarefa de Destino (Downstream Task):** Usaremos o Encoder pré-treinado para uma tarefa de classificação de imagens, usando **apenas uma pequena fração** dos rótulos. Vamos provar que essa abordagem supera em muito um modelo treinado do zero com os mesmos poucos rótulos.\n"
      ],
      "metadata": {
        "id": "QQHzgF6vk8mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descomente e execute se não tiver a biblioteca instalada\n",
        "# !pip install tensorflow_datasets\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"TensorFlow versão: {tf.__version__}\")"
      ],
      "metadata": {
        "id": "Cw1OqV4Lk9hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando o dataset CIFAR-10\n",
        "# Para o pré-treinamento SSL, vamos ignorar os rótulos.\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'cifar10',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "# --- Hiperparâmetros ---\n",
        "BATCH_SIZE = 128\n",
        "IMG_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Função para normalizar as imagens para o intervalo [0, 1]\n",
        "def normalize_img(image, label):\n",
        "    return (tf.cast(image, tf.float32) / 255.0, label)\n",
        "\n",
        "# Pipeline de dados para o pré-treinamento (sem rótulos)\n",
        "ds_train_unsupervised = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE).shuffle(1024).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "# Pipeline de dados para a tarefa de classificação (com rótulos)\n",
        "ds_train_supervised = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "ds_test_supervised = ds_test.map(normalize_img, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "print(\"Dataset CIFAR-10 carregado e preparado.\")\n"
      ],
      "metadata": {
        "id": "gXpyZradlCgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Esta é a parte central da nossa tarefa de pretexto. Criamos duas \"visões\" diferentes e aleatórias da mesma imagem.\n",
        "\"\"\"\n",
        "\n",
        "data_augmentation = models.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "    layers.RandomContrast(0.2)\n",
        "], name=\"data_augmentation\")\n"
      ],
      "metadata": {
        "id": "wGEUhR01lF6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_encoder():\n",
        "    # Usando uma ResNet como nosso encoder para aprender as representações\n",
        "    # include_top=False remove a camada final de classificação\n",
        "    resnet = tf.keras.applications.ResNet50V2(include_top=False, weights=None, input_shape=(IMG_SIZE, IMG_SIZE, 3), pooling='avg')\n",
        "    return models.Sequential([\n",
        "        layers.Input((IMG_SIZE, IMG_SIZE, 3)),\n",
        "        data_augmentation, # Aplicar aumento nos dados de entrada\n",
        "        resnet\n",
        "    ], name='encoder')\n",
        "\n",
        "\n",
        "def get_ssl_model(encoder):\n",
        "    # A cabeça de projeção é usada apenas durante o pré-treinamento SSL\n",
        "    projection_head = models.Sequential([\n",
        "        layers.Input(shape=(encoder.output.shape[1],)),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dense(64)\n",
        "    ], name='projection_head')\n",
        "\n",
        "    # O modelo SSL completo\n",
        "    ssl_model = models.Sequential([\n",
        "        encoder,\n",
        "        projection_head\n",
        "    ], name='ssl_model')\n",
        "    return ssl_model\n",
        "\n",
        "encoder = get_encoder()\n",
        "ssl_model = get_ssl_model(encoder)\n",
        "\n",
        "ssl_model.summary()\n"
      ],
      "metadata": {
        "id": "9B2-_irJlIlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, temperature=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def call(self, z1, z2):\n",
        "        # z1 e z2 são as projeções das duas visões aumentadas do mesmo batch\n",
        "        # O formato de z1 e z2 é [batch_size, projection_dim]\n",
        "\n",
        "        # Normalizar as projeções\n",
        "        z1 = tf.math.l2_normalize(z1, axis=1)\n",
        "        z2 = tf.math.l2_normalize(z2, axis=1)\n",
        "\n",
        "        # Matriz de similaridade de cosseno\n",
        "        similarities = tf.matmul(z1, z2, transpose_b=True) / self.temperature\n",
        "\n",
        "        # Os pares positivos estão na diagonal da matriz de similaridade entre z1 e z2\n",
        "        # A perda deve maximizar a similaridade desses pares em relação a todos os outros (negativos)\n",
        "        batch_size = tf.shape(z1)[0]\n",
        "        labels = tf.range(batch_size)\n",
        "        loss = tf.keras.losses.sparse_categorical_crossentropy(labels, similarities, from_logits=True)\n",
        "        return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "R2tUGfo2lLKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nIniciando o pré-treinamento autossupervisionado...\")\n",
        "\n",
        "# Pré-treinamento por poucas épocas (na prática, seria por muito mais tempo)\n",
        "EPOCHS_SSL = 10\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_fn = ContrastiveLoss()\n",
        "\n",
        "for epoch in range(EPOCHS_SSL):\n",
        "    epoch_loss = 0\n",
        "    # Ignoramos os rótulos '_'\n",
        "    for step, (images, _) in enumerate(ds_train_unsupervised):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Gerar duas visões aumentadas e suas projeções\n",
        "            proj1 = ssl_model(images, training=True)\n",
        "            proj2 = ssl_model(images, training=True)\n",
        "\n",
        "            # Calcular a perda contrastiva\n",
        "            loss = loss_fn(proj1, proj2)\n",
        "\n",
        "        gradients = tape.gradient(loss, ssl_model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, ssl_model.trainable_variables))\n",
        "        epoch_loss += loss\n",
        "\n",
        "    print(f\"Época {epoch+1}/{EPOCHS_SSL}, Perda: {epoch_loss / (step + 1):.4f}\")\n",
        "\n",
        "print(\"Pré-treinamento SSL concluído!\")\n"
      ],
      "metadata": {
        "id": "CDd9Cu8alNuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Agora, o teste final. Vamos usar nosso encoder pré-treinado e adicionar uma camada de classificação.\n",
        "Vamos treiná-lo com apenas 10% dos dados rotulados e comparar seu desempenho com um modelo treinado do zero.\n",
        "\"\"\"\n",
        "\n",
        "def get_classifier(encoder, trainable=True):\n",
        "    # Congelar ou não os pesos do encoder\n",
        "    encoder.trainable = trainable\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "        encoder,\n",
        "        layers.Dense(10, activation='softmax') # 10 classes no CIFAR-10\n",
        "    ], name=f'classifier_trainable_{trainable}')\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Pegar apenas 10% dos dados de treino\n",
        "small_ds_train = ds_train.take(int(ds_info.splits['train'].num_examples * 0.1))\n",
        "small_ds_train = small_ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "# --- Modelo 1: Usando o Encoder SSL Pré-treinado ---\n",
        "print(\"\\n--- Treinando classificador com encoder SSL (congelado) ---\")\n",
        "classifier_ssl = get_classifier(encoder, trainable=False)\n",
        "history_ssl = classifier_ssl.fit(small_ds_train, epochs=10, validation_data=ds_test_supervised, verbose=1)\n",
        "\n",
        "# --- Modelo 2: Treinando um modelo do zero ---\n",
        "print(\"\\n--- Treinando classificador do zero ---\")\n",
        "encoder_scratch = get_encoder() # Novo encoder com pesos aleatórios\n",
        "classifier_scratch = get_classifier(encoder_scratch, trainable=True)\n",
        "history_scratch = classifier_scratch.fit(small_ds_train, epochs=10, validation_data=ds_test_supervised, verbose=1)"
      ],
      "metadata": {
        "id": "caR3-QbOlRIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ssl_acc = history_ssl.history['val_accuracy'][-1]\n",
        "scratch_acc = history_scratch.history['val_accuracy'][-1]\n",
        "\n",
        "print(\"\\n--- Resultados Finais ---\")\n",
        "print(f\"Acurácia no teste (com Encoder SSL): {ssl_acc:.4f}\")\n",
        "print(f\"Acurácia no teste (treinado do zero): {scratch_acc:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_ssl.history['val_accuracy'], label='Com SSL')\n",
        "plt.plot(history_scratch.history['val_accuracy'], label='Do Zero')\n",
        "plt.title('Acurácia de Validação por Época')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(['Com Encoder SSL', 'Do Zero'], [ssl_acc, scratch_acc], color=['cornflowerblue', 'lightcoral'])\n",
        "plt.title('Acurácia Final no Conjunto de Teste')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "RZtkUm58lUHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "### Conclusão\n",
        "\n",
        "Os resultados são claros: mesmo com um pré-treinamento SSL curto e em apenas 10% dos dados rotulados, o modelo que usou o encoder pré-treinado **superou significativamente** o modelo treinado do zero.\n",
        "\n",
        "Isso demonstra o poder do Aprendizado Autossupervisionado:\n",
        "1.  **Aprende Features Úteis:** Ao resolver a tarefa de pretexto contrastiva, o encoder aprendeu a extrair características robustas das imagens, que são muito mais úteis como ponto de partida do que pesos aleatórios.\n",
        "2.  **Reduz a Necessidade de Rótulos:** Conseguimos um desempenho superior com muito menos dados rotulados, um recurso caro e muitas vezes escasso.\n",
        "3.  **Base para Modelos de Fundação:** Esta é a filosofia por trás de gigantescos modelos de linguagem e visão (como GPT, BERT, CLIP). Eles são pré-treinados em enormes quantidades de dados não rotulados da internet, aprendendo representações ricas que podem ser adaptadas para centenas de tarefas específicas com muito pouco ajuste fino.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tQp1DNNxlWrI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}