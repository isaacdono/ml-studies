{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhl/pTYzCoa+DL5BY3Wbah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacdono/ml-studies/blob/main/gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estudo Prático: Redes Geradoras Adversariais (GANs)\n",
        "\n",
        "As GANs são um dos modelos generativos mais fascinantes em Machine Learning. Elas foram introduzidas por Ian Goodfellow em 2014.\n",
        "\n",
        "Uma GAN consiste em duas redes neurais que competem em um jogo de soma zero:\n",
        "1.  **O Gerador (Generator)**: Tenta criar dados sintéticos (ex: imagens) a partir de um ruído aleatório. Seu objetivo é criar dados tão realistas que sejam indistinguíveis dos dados reais. Pense nele como um **falsificador de arte**.\n",
        "2.  **O Discriminador (Discriminator)**: Atua como um classificador binário. Ele recebe tanto os dados reais do nosso dataset quanto os dados falsos do gerador e tenta identificar quais são reais e quais são falsos. Pense nele como um **crítico de arte**.\n",
        "\n",
        "O treinamento funciona da seguinte forma:\n",
        "-   O Discriminador é treinado para ficar melhor em diferenciar o real do falso.\n",
        "-   O Gerador é treinado para \"enganar\" o Discriminador, ou seja, para produzir dados que o Discriminador classifique como reais.\n",
        "\n",
        "Através dessa competição, o Gerador se torna progressivamente melhor na criação de dados realistas. Neste notebook, vamos construir uma **GAN Convolucional Profunda (DCGAN)** para gerar novas imagens de dígitos manuscritos (MNIST)."
      ],
      "metadata": {
        "id": "II7IbRUeSk-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "print(f\"TensorFlow versão: {tf.__version__}\")\n",
        "print(\"Bibliotecas importadas com sucesso!\")"
      ],
      "metadata": {
        "id": "TLYaX6jZSmIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Pré-processamento:\n",
        "# 1. Adicionar uma dimensão de canal (para imagens em tons de cinza)\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# 2. Normalizar os pixels para o intervalo [-1, 1].\n",
        "# A ativação 'tanh' na última camada do gerador funciona bem com esta normalização.\n",
        "x_train = (x_train - 127.5) / 127.5\n",
        "\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Criando um dataset TensorFlow para um pipeline de dados eficiente\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "print(f\"Formato dos dados de treino: {x_train.shape}\")\n",
        "print(\"Dados preparados e normalizados.\")\n"
      ],
      "metadata": {
        "id": "rqFC3VRGSrFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "O Gerador pega um vetor de ruído aleatório e o transforma em uma imagem 28x28.\n",
        "Ele usa camadas `Conv2DTranspose` para \"desconvoluir\" o vetor de ruído até o formato de uma imagem.\n",
        "\"\"\"\n",
        "def build_generator():\n",
        "    model = models.Sequential(name='Generator')\n",
        "    # Entrada: vetor de ruído (ex: 100 dimensões)\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "\n",
        "    # Camada de upsampling 1: 7x7x128\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    # Camada de upsampling 2: 14x14x64\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    # Camada de upsampling 3: 28x28x1 (imagem final)\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = build_generator()\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "gh7SCW59Sttu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "O Discriminador é um classificador de imagens convolucional padrão.\n",
        "Ele pega uma imagem 28x28 e retorna um único valor indicando a probabilidade de a imagem ser real.\n",
        "\"\"\"\n",
        "def build_discriminator():\n",
        "    model = models.Sequential(name='Discriminator')\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1)) # Saída única para classificação (real ou falso)\n",
        "\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "i06sa_zdSwe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    # O gerador quer que o discriminador pense que as imagens falsas são reais (rótulo 1)\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "COa6kJJZS0Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# Vamos reutilizar este seed para podermos visualizar a evolução das imagens\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "\n",
        "# O @tf.function compila a função em um grafo TensorFlow, o que a torna muito mais rápida.\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle(f'Imagens geradas na Época {epoch}', y=0.92)\n",
        "    # plt.savefig('image_at_epoch_{:04d}.png'.format(epoch)) # Para salvar as imagens\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "cWTRNpOWS2k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Este é o loop de treinamento principal. Para cada época, iteramos sobre os batches de dados.\n",
        "Dentro de cada `train_step`, ambas as redes são treinadas. Periodicamente, geramos e\n",
        "exibimos imagens usando nosso ruído fixo (`seed`) para ver o progresso do Gerador.\n",
        "\"\"\"\n",
        "print(\"Iniciando o treinamento da GAN... (Pode levar vários minutos)\")\n",
        "for epoch in range(EPOCHS):\n",
        "    for image_batch in train_dataset:\n",
        "        train_step(image_batch)\n",
        "\n",
        "    # A cada 5 épocas, mostramos o progresso\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Época {epoch + 1} concluída.\")\n",
        "        generate_and_save_images(generator, epoch + 1, seed)\n",
        "\n",
        "# Gerando a imagem final\n",
        "print(\"\\nTreinamento concluído! Imagens finais geradas:\")\n",
        "generate_and_save_images(generator, EPOCHS, seed)\n"
      ],
      "metadata": {
        "id": "0BbonppPS5-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "### Conclusão\n",
        "\n",
        "Neste notebook, construímos e treinamos uma GAN do zero. Pudemos observar como, a partir de puro ruído, o Gerador aprendeu a criar imagens que se assemelham a dígitos manuscritos.\n",
        "\n",
        "**Pontos importantes:**\n",
        "-   **Treinamento Adversarial:** O coração da GAN é a competição entre o Gerador e o Discriminador.\n",
        "-   **Instabilidade:** O treinamento de GANs é notoriamente instável e sensível a hiperparâmetros. Pequenas mudanças podem levar a resultados muito diferentes.\n",
        "-   **Modo Colapso (Mode Collapse):** Um problema comum onde o Gerador aprende a produzir apenas um ou alguns poucos tipos de saídas que enganam bem o Discriminador, em vez de aprender a diversidade completa dos dados.\n",
        "\n",
        "As GANs são um campo ativo e fascinante de pesquisa, com arquiteturas muito mais avançadas como StyleGAN, CycleGAN e BigGAN, que são capazes de gerar imagens fotorrealistas de alta resolução.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Cvrm7vKzS-Y3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}