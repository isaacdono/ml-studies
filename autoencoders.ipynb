{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOV7nGQWlK9PV2oH3MPGUMs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacdono/ml-studies/blob/main/autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estudo Prático: Autoencoders\n",
        "\n",
        "Um **Autoencoder** é um tipo de rede neural artificial usada para aprendizado não supervisionado de representações eficientes (codificações). O objetivo de um autoencoder é aprender uma representação (encoding) para um conjunto de dados, normalmente para redução de dimensionalidade ou extração de características.\n",
        "\n",
        "Ele consiste em duas partes principais:\n",
        "1.  **Encoder**: Uma rede que comprime os dados de entrada em uma representação latente de menor dimensão (o \"encoding\" ou \"bottleneck\").\n",
        "2.  **Decoder**: Uma rede que tenta reconstruir os dados de entrada originais a partir da representação comprimida.\n",
        "\n",
        "A rede é treinada para minimizar o **erro de reconstrução**, que é a diferença entre a entrada original e a saída reconstruída. Ao forçar os dados a passarem por um \"gargalo\" (bottleneck) de menor dimensão, a rede aprende as características mais importantes dos dados.\n",
        "\n",
        "Neste notebook, vamos construir um autoencoder simples para comprimir e reconstruir imagens do famoso dataset **MNIST**."
      ],
      "metadata": {
        "id": "L0LY5C7mRVFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "print(f\"TensorFlow versão: {tf.__version__}\")\n",
        "print(\"Bibliotecas importadas com sucesso!\")"
      ],
      "metadata": {
        "id": "JaxG94N_RWBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando o dataset. Não precisamos dos rótulos (y_train, y_test) para treinar o autoencoder,\n",
        "# mas vamos usá-los no final para visualização.\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Pré-processamento:\n",
        "# 1. Normalizar os pixels para o intervalo [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# 2. Achatar as imagens 28x28 em vetores de 784 dimensões\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "print(f\"Formato dos dados de treino: {x_train.shape}\")\n",
        "print(f\"Formato dos dados de teste:  {x_test.shape}\")"
      ],
      "metadata": {
        "id": "nSxtOlL0RZPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Vamos construir nosso modelo usando a API Funcional do Keras, que é ótima para visualizar arquiteturas não-sequenciais como esta.\n",
        "\n",
        "A imagem original (784 dimensões) será comprimida para uma representação latente de apenas 32 dimensões.\n",
        "\"\"\"\n",
        "# Tamanho da nossa representação codificada (o bottleneck)\n",
        "encoding_dim = 32\n",
        "\n",
        "# Camada de entrada\n",
        "input_img = Input(shape=(784,))\n",
        "\n",
        "# --- ENCODER ---\n",
        "# \"encoded\" é a representação comprimida da entrada\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(encoding_dim, activation='relu')(encoded) # A representação do bottleneck\n",
        "\n",
        "# --- DECODER ---\n",
        "# \"decoded\" é a reconstrução da imagem a partir do bottleneck\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded) # 'sigmoid' para manter os valores entre 0 e 1\n",
        "\n",
        "# --- AUTOENCODER MODEL ---\n",
        "# Este modelo mapeia uma entrada para sua reconstrução\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compilando o modelo. O objetivo é minimizar a diferença entre input e output.\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "o_HkdmP3RbqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Para treinar, usamos `x_train` tanto como dados de entrada quanto como o alvo da predição.\n",
        "A rede aprende a gerar `x_train` a partir de `x_train`.\n",
        "\"\"\"\n",
        "history = autoencoder.fit(x_train, x_train, # Note: input e target são os mesmos\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                verbose=1)\n",
        "\n",
        "# Plotando a perda de treino e validação\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Perda de Treino')\n",
        "plt.plot(history.history['val_loss'], label='Perda de Validação')\n",
        "plt.title('Histórico de Perda do Modelo')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Época')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fCOPbOakRfCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Agora, o momento da verdade! Vamos pegar algumas imagens do conjunto de teste,\n",
        "passá-las pelo autoencoder e comparar as imagens originais com as reconstruídas.\n",
        "\"\"\"\n",
        "\n",
        "# Usando o modelo treinado para prever (reconstruir) as imagens de teste\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "# Plotando os resultados\n",
        "n = 10  # Quantidade de dígitos para exibir\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Imagem original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    if i == 0:\n",
        "        ax.set_title(\"Original\", loc='left')\n",
        "\n",
        "    # Imagem reconstruída\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    if i == 0:\n",
        "        ax.set_title(\"Reconstruída\", loc='left')\n",
        "\n",
        "plt.suptitle(\"Comparação: Imagens Originais vs. Reconstruídas\", fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "**Observação:** As imagens reconstruídas são um pouco borradas, o que é esperado.\n",
        "Isso acontece porque o autoencoder é um modelo com perdas (*lossy*).\n",
        " No entanto, ele conseguiu capturar as características essenciais para\n",
        " reconstruir uma versão reconhecível do dígito original, mesmo após a\n",
        " compressão massiva de 784 para 32 dimensões.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YqwampdnRhiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "O que a representação comprimida (espaço latente) aprendeu?\n",
        "Se construirmos um modelo onde o `encoding_dim` é 2, podemos plotar a representação de cada dígito em um gráfico 2D e ver se o autoencoder aprendeu a agrupar dígitos semelhantes.\n",
        "\"\"\"\n",
        "# Criando um modelo separado apenas para o encoder\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "# Passando as imagens de teste pelo encoder para obter suas representações no espaço latente\n",
        "x_test_encoded = encoder.predict(x_test)\n",
        "\n",
        "# Plotando o espaço latente 2D\n",
        "plt.figure(figsize=(12, 10))\n",
        "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test, cmap='viridis')\n",
        "plt.colorbar(label='Rótulo do Dígito')\n",
        "plt.title('Visualização do Espaço Latente do Autoencoder (32D -> 2D)')\n",
        "plt.xlabel('Dimensão Latente 1')\n",
        "plt.ylabel('Dimensão Latente 2')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "**Conclusão:** Mesmo sem usar os rótulos durante o treino, o autoencoder aprendeu a organizar o espaço latente de forma que dígitos visualmente semelhantes fiquem próximos uns dos outros. Isso demonstra sua poderosa capacidade de extração de características de forma não supervisionada. Vemos clusters distintos para os diferentes dígitos, o que é um resultado impressionante.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "OdbQ9ERwRtCD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}