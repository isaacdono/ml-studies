{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSMP2ijBPNxjfhzAN2mYrA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacdono/ml-studies/blob/main/matrix_factorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estudo Prático: Fatoração de Matrizes (Matrix Factorization)\n",
        "\n",
        "A Fatoração de Matrizes é uma das técnicas mais poderosas e populares para sistemas de recomendação. É um método de **Filtragem Colaborativa baseada em modelo**.\n",
        "\n",
        "A ideia principal é decompor a matriz de avaliações (geralmente esparsa) `R` em duas matrizes de dimensões menores, `P` e `Q`.\n",
        "\n",
        "-   **R (m x n)**: Matriz de avaliações, com `m` usuários e `n` itens.\n",
        "-   **P (m x k)**: Matriz de **fatores latentes dos usuários**. Cada linha é um vetor que representa o perfil de um usuário.\n",
        "-   **Q (n x k)**: Matriz de **fatores latentes dos itens**. Cada linha é um vetor que representa o perfil de um item.\n",
        "\n",
        "O objetivo é encontrar `P` e `Q` tal que o produto $P \\times Q^T$ se aproxime da matriz original `R`. Os valores \"descobertos\" nessa nova matriz preenchida são as nossas previsões de notas.\n",
        "\n",
        "$R \\approx P \\times Q^T$\n",
        "\n",
        "Os **fatores latentes (k)** são características abstratas que o algoritmo aprende sozinho (ex: para filmes, pode ser \"nível de comédia\", \"quantidade de ação\", \"drama\", etc.).\n",
        "\n",
        "Neste notebook, usaremos a biblioteca `surprise` para aplicar o **SVD (Singular Value Decomposition)**, um popular algoritmo de fatoração de matrizes."
      ],
      "metadata": {
        "id": "qgllix20QA2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A biblioteca 'surprise' é específica para sistemas de recomendação.\n",
        "# Se não a tiver, descomente e execute a linha abaixo.\n",
        "# !pip install scikit-surprise\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso!\")"
      ],
      "metadata": {
        "id": "1SNgcSfjQBwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usaremos o mesmo dataset do notebook anterior para manter a consistência.\n",
        "data = {\n",
        "    'Ana': {'Matrix': 5, 'Titanic': 3, 'O Poderoso Chefão': 4, 'Forrest Gump': None, 'Interestelar': 5},\n",
        "    'Bruno': {'Matrix': 5, 'Titanic': 2, 'O Poderoso Chefão': None, 'Forrest Gump': 3, 'Interestelar': 4},\n",
        "    'Carla': {'Matrix': 2, 'Titanic': 5, 'O Poderoso Chefão': 2, 'Forrest Gump': 5, 'Interestelar': 2},\n",
        "    'Daniel': {'Matrix': None, 'Titanic': 4, 'O Poderoso Chefão': 5, 'Forrest Gump': 5, 'Interestelar': None},\n",
        "    'Elisa': {'Matrix': 4, 'Titanic': None, 'O Poderoso Chefão': 5, 'Forrest Gump': 2, 'Interestelar': 5}\n",
        "}\n",
        "ratings_df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Matriz Original de Avaliações:\")\n",
        "print(ratings_df)\n",
        "\n",
        "# A biblioteca 'surprise' precisa dos dados em um formato \"longo\": (usuário, item, avaliação).\n",
        "# Vamos converter nosso DataFrame.\n",
        "df_long = ratings_df.stack().reset_index()\n",
        "df_long.columns = ['item', 'user', 'rating']\n",
        "\n",
        "print(\"\\n\\nDados no formato 'longo' para o Surprise:\")\n",
        "print(df_long.head())\n",
        "\n",
        "# Agora, carregamos os dados no formato que o Surprise entende.\n",
        "# O Reader define a escala das notas (1 a 5).\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data_surprise = Dataset.load_from_df(df_long[['user', 'item', 'rating']], reader)\n",
        "\n",
        "# Vamos usar o conjunto de dados completo para treinar e ver como ele preenche os vazios.\n",
        "trainset = data_surprise.build_full_trainset()\n",
        "print(\"\\nDados carregados no Surprise com sucesso.\")"
      ],
      "metadata": {
        "id": "U9Ven_JpQMPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "### Passo 1: Treinar o Modelo\n",
        "\n",
        "Instanciamos o SVD, definindo o número de fatores latentes (`n_factors`). Este é o `k` da nossa explicação. Um `k` pequeno ajuda a generalizar e evitar overfitting.\n",
        "\"\"\"\n",
        "\n",
        "# Usando k=2 fatores latentes para este exemplo\n",
        "algo = SVD(n_factors=2, random_state=42)\n",
        "\n",
        "# Treinando o algoritmo com nossos dados\n",
        "algo.fit(trainset)\n",
        "\n",
        "print(\"Modelo SVD treinado!\")"
      ],
      "metadata": {
        "id": "tZQt-epfQRPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "### Passo 2: Prever Notas Faltantes\n",
        "\n",
        "O principal objetivo da fatoração de matrizes é prever as notas que não existem. Vamos prever qual nota a `Ana` daria para `Forrest Gump`.\n",
        "\"\"\"\n",
        "user_to_predict = 'Ana'\n",
        "item_to_predict = 'Forrest Gump'\n",
        "\n",
        "# A nota original era NaN (não avaliado)\n",
        "original_rating = ratings_df.loc[item_to_predict, user_to_predict]\n",
        "print(f\"Nota original de '{user_to_predict}' para '{item_to_predict}': {original_rating}\")\n",
        "\n",
        "# Fazendo a previsão\n",
        "prediction = algo.predict(uid=user_to_predict, iid=item_to_predict)\n",
        "predicted_rating = prediction.est\n",
        "\n",
        "print(f\"Nota prevista pelo SVD: {predicted_rating:.2f}\")\n"
      ],
      "metadata": {
        "id": "CYJuyMzZQT_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "### Passo 3: Visualizar a Matriz Reconstruída\n",
        "\n",
        "Vamos usar nosso modelo treinado para preencher TODOS os valores, incluindo os que já existiam e os que estavam faltando, para ver a matriz completa.\n",
        "\"\"\"\n",
        "# Criando uma cópia da matriz original para preencher com as previsões\n",
        "reconstructed_df = ratings_df.copy()\n",
        "\n",
        "# Iterando por todos os usuários e itens para preencher a matriz\n",
        "for user in ratings_df.columns:\n",
        "    for item in ratings_df.index:\n",
        "        reconstructed_df.loc[item, user] = algo.predict(uid=user, iid=item).est\n",
        "\n",
        "print(\"Matriz Original (com valores NaN):\")\n",
        "display(ratings_df.style.highlight_null(null_color='lightgray'))\n",
        "\n",
        "print(\"\\nMatriz Reconstruída e Preenchida pelo SVD:\")\n",
        "display(reconstructed_df.style.background_gradient(cmap='viridis'))\n"
      ],
      "metadata": {
        "id": "5jxNlifJQY9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "### Passo 4 (Avançado): Olhando as Matrizes P e Q\n",
        "\n",
        "Podemos inspecionar as matrizes de fatores latentes `P` (usuários) e `Q` (itens) que o SVD aprendeu. Cada linha é o \"perfil\" de um usuário ou item em um espaço de `k=2` dimensões.\n",
        "\"\"\"\n",
        "# Obtendo as matrizes P e Q do modelo treinado\n",
        "P = algo.pu # Fatores dos usuários (n_users x k)\n",
        "Q = algo.qi # Fatores dos itens (n_items x k)\n",
        "\n",
        "# Mapeando os IDs internos do Surprise para os nomes originais\n",
        "user_map = [trainset.to_raw_uid(inner_id) for inner_id in range(trainset.n_users)]\n",
        "item_map = [trainset.to_raw_iid(inner_id) for inner_id in range(trainset.n_items)]\n",
        "\n",
        "# Criando DataFrames para P e Q\n",
        "df_P = pd.DataFrame(P, index=user_map, columns=['Fator_1', 'Fator_2'])\n",
        "df_Q = pd.DataFrame(Q, index=item_map, columns=['Fator_1', 'Fator_2'])\n",
        "\n",
        "print(\"Matriz P (Perfis dos Usuários):\")\n",
        "print(df_P)\n",
        "\n",
        "print(\"\\nMatriz Q (Perfis dos Itens):\")\n",
        "print(df_Q)\n",
        "\n",
        "# Verificação: o produto P * Q.T deve ser próximo da matriz reconstruída\n",
        "# Pegando os vetores para 'Ana' e 'Matrix'\n",
        "ana_vector = df_P.loc['Ana'].values\n",
        "matrix_vector = df_Q.loc['Matrix'].values\n",
        "\n",
        "# Adicionando os \"biases\" (vieses) que o SVD também aprende\n",
        "ana_bias = algo.bu[trainset.to_inner_uid('Ana')]\n",
        "matrix_bias = algo.bi[trainset.to_inner_iid('Matrix')]\n",
        "global_mean = trainset.global_mean\n",
        "\n",
        "predicted_rating_manual = global_mean + ana_bias + matrix_bias + np.dot(ana_vector, matrix_vector)\n",
        "print(f\"\\nPrevisão manual para (Ana, Matrix) via dot product: {predicted_rating_manual:.2f}\")\n",
        "print(f\"Previsão do modelo para (Ana, Matrix): {reconstructed_df.loc['Matrix', 'Ana']:.2f}\")\n"
      ],
      "metadata": {
        "id": "9u4EaMDOQcWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "### Conclusão\n",
        "\n",
        "A Fatoração de Matrizes é uma abordagem poderosa que vai além de simplesmente encontrar vizinhos. Ela aprende **representações latentes** (perfis) para usuários e itens.\n",
        "\n",
        "**Vantagens:**\n",
        "-   **Generalização:** O modelo aprende características gerais, o que o ajuda a fazer previsões mesmo para usuários ou itens com poucas avaliações.\n",
        "-   **Esparsidade:** Lida muito bem com matrizes esparsas (com muitos valores faltantes), que é o caso comum em cenários reais.\n",
        "-   **Escalabilidade:** É computacionalmente mais eficiente para fazer previsões do que os métodos baseados em vizinhança em larga escala.\n",
        "\n",
        "Este método é a base de muitos sistemas de recomendação modernos e sofisticados.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OJzVR5KrQgfb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}